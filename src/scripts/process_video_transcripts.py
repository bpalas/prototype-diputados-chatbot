# src/etl/process_video_transcripts.py
# -*- coding: utf-8 -*-

"""
Orquestador principal para procesar videos de comisiones: descarga, transcribe
con diarizaciÃ³n, identifica hablantes con un LLM y carga los turnos de habla
en la base de datos.
"""

import os
import pandas as pd
import sqlite3
from openai import OpenAI
from google.cloud import speech, storage
import yt_dlp
import json
from dotenv import load_dotenv
import time

# --- 1. CONFIGURACIÃ“N ---
load_dotenv() # Carga las variables de entorno desde el archivo .env

# Cliente de OpenAI
if not os.getenv("OPENAI_API_KEY"):
    raise ValueError("La variable de entorno OPENAI_API_KEY no estÃ¡ configurada.")
client = OpenAI()

# Cliente de Google Cloud (se autentica automÃ¡ticamente con la variable de entorno)
if not os.getenv("GOOGLE_APPLICATION_CREDENTIALS"):
    raise ValueError("La variable de entorno GOOGLE_APPLICATION_CREDENTIALS no estÃ¡ configurada.")

# Rutas del proyecto
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
DB_PATH = os.path.join(PROJECT_ROOT, 'data', 'database', 'parlamento.db')
INPUT_CSV_PATH = os.path.join(PROJECT_ROOT, 'data', 'video_processing', 'playlists', 'playlists 2025', 'comisiones_2025_enlazado.csv')
AUDIO_CACHE_PATH = os.path.join(PROJECT_ROOT, 'data', 'audio_cache')
os.makedirs(AUDIO_CACHE_PATH, exist_ok=True)

# ConfiguraciÃ³n de GCP (Â¡Â¡CORREGIDO!!)
GCS_BUCKET_NAME = 'audios-chatbot-diputados-bpalas-2025'

def get_miembros_comision(comision_id: int) -> pd.DataFrame:

    """Obtiene los miembros de una comisiÃ³n especÃ­fica desde la BD."""
    with sqlite3.connect(DB_PATH) as conn:
        query = """
            SELECT p.mp_uid, p.nombre_completo
            FROM comision_membresias cm
            JOIN dim_parlamentario p ON cm.mp_uid = p.mp_uid
            WHERE cm.comision_id = ?
        """
        df = pd.read_sql_query(query, conn, params=(comision_id,))
    return df

# Reemplaza la funciÃ³n download_audio en src/etl/process_video_transcripts.py con esta:
# Reemplaza tu funciÃ³n download_audio con esta versiÃ³n final
# Reemplaza esta funciÃ³n en src/scripts/process_video_transcripts.py
def download_audio(video_url: str, video_id: str) -> str | None:
    """
    Descarga y convierte el audio a formato FLAC MONO, que es ideal para
    la API de Google Speech-to-Text. Requiere ffmpeg.
    """
    output_template = os.path.join(AUDIO_CACHE_PATH, f"{video_id}.flac")

    if os.path.exists(output_template):
        print(f"  -> Audio ya existe en cachÃ©: {output_template}")
        return output_template

    print(f"  -> Descargando y convirtiendo audio para '{video_url}' a FLAC MONO...")

    ydl_opts = {
        'format': 'bestaudio/best',
        # Usamos outtmpl para definir el nombre FINAL del archivo.
        'outtmpl': os.path.join(AUDIO_CACHE_PATH, video_id),
        'quiet': False,
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'flac',
        }],
        # Forzamos la conversiÃ³n a 1 canal de audio (mono)
        'postprocessor_args': [
            '-ac', '1'
        ],
    }

    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            ydl.download([video_url])
        
        # El archivo final tendrÃ¡ la extensiÃ³n .flac aÃ±adida por el postprocesador
        final_filepath = os.path.join(AUDIO_CACHE_PATH, f"{video_id}.flac")
        
        if os.path.exists(final_filepath):
            print(f"  -> Descarga y conversiÃ³n completada: {final_filepath}")
            return final_filepath
        else:
            # Fallback por si algo sale mal con los nombres
            raise FileNotFoundError(f"El archivo convertido {final_filepath} no fue encontrado.")

    except Exception as e:
        print(f"  âŒ Error al descargar/convertir con yt-dlp: {e}")
        print("  -> AsegÃºrate de que FFmpeg estÃ© instalado y accesible en el PATH del sistema.")
        return None
def upload_to_gcs(source_file_path: str, destination_blob_name: str):
    """Sube un archivo a Google Cloud Storage."""
    storage_client = storage.Client()
    bucket = storage_client.bucket(GCS_BUCKET_NAME)
    blob = bucket.blob(destination_blob_name)
    print(f"  -> Subiendo a GCS: gs://{GCS_BUCKET_NAME}/{destination_blob_name}")
    blob.upload_from_filename(source_file_path)
# Reemplaza esta funciÃ³n en src/scripts/process_video_transcripts.py
# Reemplaza esta funciÃ³n en src/scripts/process_video_transcripts.py
def transcribe_gcs_audio_with_diarization(gcs_uri: str):
    """TranscripciÃ³n con diarizaciÃ³n activada."""
    client = speech.SpeechClient()
    audio = speech.RecognitionAudio(uri=gcs_uri)
    
    diarization_config = speech.SpeakerDiarizationConfig(
        enable_speaker_diarization=True, min_speaker_count=2, max_speaker_count=15
    )
    
    config = speech.RecognitionConfig(
        language_code="es-CL",
        enable_automatic_punctuation=True,
        diarization_config=diarization_config,
        audio_channel_count=1,
        # La lÃ­nea 'model="video",' ha sido eliminada.
    )
    
    print("  -> Iniciando trabajo de transcripciÃ³n en GCP...")
    operation = client.long_running_recognize(config=config, audio=audio)
    
    print("  -> Esperando a que finalice la transcripciÃ³n (esto puede tardar MUCHO tiempo)...")
    
    # Mantenemos el timeout largo, Â¡esto es importante!
    response = operation.result(timeout=10800) 
    return response

def identify_speakers_with_llm(transcript_text: str, miembros_comision_df: pd.DataFrame) -> dict:
    """Usa un LLM para mapear etiquetas de hablante a mp_uid."""
    if miembros_comision_df.empty:
        print("  -> âš ï¸ No hay miembros de comisiÃ³n para identificar. Se omitirÃ¡ la identificaciÃ³n.")
        return {}

    miembros_json_str = miembros_comision_df.to_json(orient='records', force_ascii=False)
    
    system_prompt = f"""
    Eres un asistente experto en analizar transcripciones del Congreso de Chile.
    Tu tarea es leer una transcripciÃ³n con etiquetas de hablante genÃ©ricas (ej. "Hablante 1")
    y asignar cada hablante a un parlamentario de la lista de miembros de la comisiÃ³n.

    Lista de posibles hablantes (miembros de la comisiÃ³n):
    {miembros_json_str}

    Analiza la siguiente transcripciÃ³n. Considera roles (como "presidente", "secretario") o pistas en el diÃ¡logo para hacer la asignaciÃ³n.
    Devuelve un objeto JSON que mapee cada 'speaker_tag' (el nÃºmero del hablante como string) al 'mp_uid' correcto (como nÃºmero).
    
    Ejemplo de respuesta: {{ "1": 123, "2": 456 }}
    
    Si no puedes identificar a un hablante con certeza, omÃ­telo del JSON de respuesta.
    """

    print("  -> Usando LLM (OpenAI) para identificar hablantes...")
    try:
        response = client.chat.completions.create(
            model="gpt-4o", # Modelo potente para esta tarea compleja
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"TranscripciÃ³n:\n{transcript_text}"}
            ],
            response_format={"type": "json_object"},
            temperature=0.0,
        )
        
        mapping_str_keys = json.loads(response.choices[0].message.content)
        # Convertir las claves del JSON (que son string) a enteros
        return {int(k): v for k, v in mapping_str_keys.items()}
    except Exception as e:
        print(f"  -> âŒ Error en la API de OpenAI durante la identificaciÃ³n: {e}")
        return {}


def process_and_load_turns(response, video_info, speaker_mapping, conn):
    """Agrupa las palabras por hablante y carga los turnos en la base de datos."""
    if not (response.results and response.results[-1].alternatives):
        print("  -> âš ï¸ La respuesta de transcripciÃ³n estÃ¡ vacÃ­a. No se cargarÃ¡n datos.")
        return

    words = response.results[-1].alternatives[0].words
    if not words: return

    speech_turns = []
    current_turn = None

    for word in words:
        speaker_tag = word.speaker_tag
        mp_uid = speaker_mapping.get(speaker_tag)
        if not mp_uid: continue # Omitir si el hablante no fue identificado

        if current_turn and current_turn['mp_uid'] == mp_uid:
            # Continuar el turno actual, aÃ±adiendo la palabra
            current_turn['texto'] += f" {word.word}"
            current_turn['fin_seg'] = word.end_time.total_seconds()
        else:
            # Si hay un turno anterior, guardarlo
            if current_turn:
                speech_turns.append(current_turn)
            
            # Empezar un nuevo turno de habla
            current_turn = {
                "mp_uid": mp_uid,
                "comision_id": video_info["comision_id"],
                "texto": word.word,
                "fecha": video_info["fecha"],
                "tema": video_info["title"],
                "url_video": video_info["video_url"],
                "inicio_seg": word.start_time.total_seconds(),
                "fin_seg": word.end_time.total_seconds(),
            }
            
    if current_turn:
        speech_turns.append(current_turn)

    if not speech_turns:
        print("  -> âš ï¸ No se pudieron construir turnos de habla a partir de la transcripciÃ³n.")
        return

    cursor = conn.cursor()
    for turn in speech_turns:
        cursor.execute("""
            INSERT INTO speech_turns (mp_uid, comision_id, texto, fecha, tema, url_video, inicio_seg, fin_seg)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            turn['mp_uid'], int(turn['comision_id']), turn['texto'], turn['fecha'],
            turn['tema'], turn['url_video'], turn['inicio_seg'], turn['fin_seg']
        ))
    conn.commit()
    print(f"  âœ… Se insertaron {len(speech_turns)} turnos de habla en la base de datos.")


def main():
    """FunciÃ³n principal que orquesta todo el pipeline."""
    try:
        df_videos = pd.read_csv(INPUT_CSV_PATH).dropna(subset=['comision_id', 'fecha'])
    except FileNotFoundError:
        print(f"âŒ Error: No se encontrÃ³ el archivo de manifiesto en '{INPUT_CSV_PATH}'.")
        print("AsegÃºrate de ejecutar primero 'fetch_playlist.py' y 'link_videos_to_comisiones.py'.")
        return

    for _, video_row in df_videos.iterrows():
        print(f"\nâ–¶ï¸  Procesando video: {video_row['title']}")
        
        audio_path = download_audio(video_row['video_url'], video_row['video_id'])
        if not audio_path: continue

        try:
            gcs_blob = f"transcripts/{os.path.basename(audio_path)}"
            gcs_uri = f"gs://{GCS_BUCKET_NAME}/{gcs_blob}"
            upload_to_gcs(audio_path, gcs_blob)
            
            gcp_response = transcribe_gcs_audio_with_diarization(gcs_uri)
            
            # Construir el texto completo para el LLM
            full_transcript_text = ""
            if gcp_response.results:
                # Agrupar por hablante para dar mÃ¡s contexto al LLM
                speaker_text = {}
                for result in gcp_response.results:
                    for word_info in result.alternatives[0].words:
                        tag = word_info.speaker_tag
                        if tag not in speaker_text:
                            speaker_text[tag] = []
                        speaker_text[tag].append(word_info.word)
                
                for tag, words in sorted(speaker_text.items()):
                    full_transcript_text += f"\nHablante {tag}: {' '.join(words)}\n"
            
            if not full_transcript_text:
                print("  -> âš ï¸ La transcripciÃ³n de GCP estÃ¡ vacÃ­a. Saltando al siguiente video.")
                continue

            miembros_df = get_miembros_comision(int(video_row['comision_id']))
            speaker_map = identify_speakers_with_llm(full_transcript_text, miembros_df)
            
            if not speaker_map:
                print("  -> âš ï¸ El LLM no pudo identificar a los hablantes. No se cargarÃ¡n datos para este video.")
                continue

            with sqlite3.connect(DB_PATH) as conn:
                process_and_load_turns(gcp_response, video_row.to_dict(), speaker_map, conn)

        except Exception as e:
            print(f"  âŒ OcurriÃ³ un error general procesando el video {video_row['video_id']}: {e}")
        finally:
            # Limpiar el archivo de audio local despuÃ©s de procesar
            if os.path.exists(audio_path):
                os.remove(audio_path)

    print("\nğŸ‰ --- Proceso de TranscripciÃ³n y Carga Finalizado --- ğŸ‰")

if __name__ == "__main__":
    main()